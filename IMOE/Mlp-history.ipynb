{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import argparse\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "conditions = [ 'CY45-05_1', 'CY35-05_1', 'CY25-05_1']\n",
    "\n",
    "results = pd.DataFrame(columns=['condition', 'trial', 'train_loss', 'val_loss', 'test_rmse', 'test_mape'])\n",
    "\n",
    "for condition in conditions:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Starting experiments for condition: {condition}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    for trial in range(10):\n",
    "        print(f\"\\nTrial {trial+1}/10 for {condition}\")\n",
    "\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument('--condition', type=str, default=condition)\n",
    "        parser.add_argument('--window_size', type=int, default=10)\n",
    "        parser.add_argument('--prediction_steps', type=int, default=100)\n",
    "        parser.add_argument('--step_size', type=int, default=1)\n",
    "        parser.add_argument('--epochs', type=int, default=500)\n",
    "        parser.add_argument('--batch_size', type=int, default=64)\n",
    "        parser.add_argument('--lr', type=float, default=0.0001)\n",
    "\n",
    "        args = parser.parse_args([])\n",
    "\n",
    "        if args.condition == 'CY45-05_1':\n",
    "            train_files = [\n",
    "                'CY45-05_1-#1.csv', 'CY45-05_1-#2.csv', 'CY45-05_1-#3.csv', 'CY45-05_1-#4.csv',\n",
    "                'CY45-05_1-#5.csv', 'CY45-05_1-#6.csv', 'CY45-05_1-#7.csv', 'CY45-05_1-#8.csv',\n",
    "                'CY45-05_1-#9.csv', 'CY45-05_1-#10.csv', 'CY45-05_1-#11.csv', 'CY45-05_1-#12.csv',\n",
    "                'CY45-05_1-#13.csv', 'CY45-05_1-#14.csv', 'CY45-05_1-#15.csv', 'CY45-05_1-#16.csv',\n",
    "                'CY45-05_1-#17.csv'\n",
    "            ]\n",
    "            val_files = [\n",
    "                'CY45-05_1-#28.csv', 'CY45-05_1-#25.csv'\n",
    "            ]\n",
    "            test_files = [\n",
    "                'CY45-05_1-#24.csv', 'CY45-05_1-#26.csv', 'CY45-05_1-#27.csv', 'CY45-05_1-#22.csv',\n",
    "                'CY45-05_1-#23.csv'\n",
    "            ]\n",
    "        elif args.condition == 'CY25-05_1':\n",
    "            train_files = [\n",
    "                'CY25-05_1-#2.csv', 'CY25-05_1-#3.csv', 'CY25-05_1-#4.csv',\n",
    "                'CY25-05_1-#5.csv', 'CY25-05_1-#6.csv', 'CY25-05_1-#7.csv', 'CY25-05_1-#8.csv',\n",
    "                'CY25-05_1-#9.csv', 'CY25-05_1-#10.csv', 'CY25-05_1-#11.csv', 'CY25-05_1-#13.csv'\n",
    "            ]\n",
    "            val_files = [\n",
    "                'CY25-05_1-#18.csv', 'CY25-05_1-#19.csv'\n",
    "            ]\n",
    "            test_files = [\n",
    "                'CY25-05_1-#1.csv', 'CY25-05_1-#14.csv', 'CY25-05_1-#15.csv', 'CY25-05_1-#16.csv',\n",
    "                'CY25-05_1-#17.csv', 'CY25-05_1-#12.csv'\n",
    "            ]\n",
    "        elif args.condition == 'CY25-025_1':\n",
    "            train_files = [\n",
    "                'CY25-025_1-#1.csv', 'CY25-025_1-#2.csv', 'CY25-025_1-#3.csv'\n",
    "            ]\n",
    "            val_files = [\n",
    "                'CY25-025_1-#7.csv'\n",
    "            ]\n",
    "            test_files = [\n",
    "                'CY25-025_1-#5.csv', 'CY25-025_1-#6.csv', 'CY25-025_1-#4.csv'\n",
    "            ]\n",
    "        elif args.condition == 'CY25-1_1':\n",
    "            train_files = [\n",
    "                'CY25-1_1-#1.csv', 'CY25-1_1-#2.csv', 'CY25-1_1-#3.csv', 'CY25-1_1-#4.csv', 'CY25-1_1-#5.csv'\n",
    "            ]\n",
    "            val_files = [\n",
    "                'CY25-1_1-#6.csv'\n",
    "            ]\n",
    "            test_files = [\n",
    "                'CY25-1_1-#7.csv', 'CY25-1_1-#8.csv', 'CY25-1_1-#9.csv'\n",
    "            ]\n",
    "        elif args.condition == 'CY35-05_1':\n",
    "            train_files = [\n",
    "                'CY35-05_1-#1.csv'\n",
    "            ]\n",
    "            val_files = [\n",
    "                'CY35-05_1-#2.csv'\n",
    "            ]\n",
    "            test_files = [\n",
    "                'CY35-05_1-#3.csv'\n",
    "            ]\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported condition: {args.condition}\")\n",
    "\n",
    "        input_folder = 'dataset/UL-NCA/' \n",
    "        \n",
    "        def load_battery_data(filename):\n",
    "            data = pd.read_csv(f\"{input_folder}/{filename}\")\n",
    "            return data['Discharge_Capacity'].values / 1000  # Normalization\n",
    "\n",
    "        def create_sequences(data, window_size, prediction_steps, step_size):\n",
    "            X, y = [], []\n",
    "            for start_idx in range(0, len(data) - window_size - prediction_steps + 1, step_size):\n",
    "                X.append(data[start_idx:start_idx+window_size])\n",
    "                y.append(data[start_idx+window_size:start_idx+window_size+prediction_steps])\n",
    "            return np.array(X), np.array(y)\n",
    "\n",
    "        def prepare_data(files):\n",
    "            X_all, y_all = [], []\n",
    "            for file in files:\n",
    "                data = load_battery_data(file)\n",
    "                X, y = create_sequences(data, args.window_size, args.prediction_steps, args.step_size)\n",
    "                X_all.append(X)\n",
    "                y_all.append(y)\n",
    "            return np.concatenate(X_all), np.concatenate(y_all)\n",
    "\n",
    "        X_train, y_train = prepare_data(train_files)\n",
    "        X_val, y_val = prepare_data(val_files)\n",
    "        X_test, y_test = prepare_data(test_files)\n",
    "        def to_tensor(data, device):\n",
    "            return torch.FloatTensor(data).to(device)\n",
    "        X_train_t = to_tensor(X_train, device)\n",
    "        y_train_t = to_tensor(y_train, device)\n",
    "        X_val_t = to_tensor(X_val, device)\n",
    "        y_val_t = to_tensor(y_val, device)\n",
    "        X_test_t = to_tensor(X_test, device)\n",
    "        y_test_t = to_tensor(y_test, device)\n",
    "        train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "        val_dataset = TensorDataset(X_val_t, y_val_t)\n",
    "        test_dataset = TensorDataset(X_test_t, y_test_t)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=args.batch_size)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1)\n",
    "        class BatteryMLP(nn.Module):\n",
    "            def __init__(self, input_size, output_size):\n",
    "                super().__init__()\n",
    "                self.net = nn.Sequential(\n",
    "                    nn.Linear(input_size, 128),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.2),\n",
    "                    nn.Linear(128, 64),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.2),\n",
    "                    nn.Linear(64, output_size)\n",
    "                )\n",
    "                \n",
    "            def forward(self, x):\n",
    "                return self.net(x)\n",
    "\n",
    "        model = BatteryMLP(args.window_size, args.prediction_steps).to(device)\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=100, factor=0.5)\n",
    "\n",
    "        def train_epoch(model, loader, optimizer, criterion, device):\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            for X_batch, y_batch in loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "            return total_loss / len(loader)\n",
    "\n",
    "        def evaluate(model, loader, criterion, device):\n",
    "            model.eval()\n",
    "            total_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for X_batch, y_batch in loader:\n",
    "                    X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                    outputs = model(X_batch)\n",
    "                    total_loss += criterion(outputs, y_batch).item()\n",
    "            return total_loss / len(loader)\n",
    "\n",
    "        train_losses, val_losses = [], []\n",
    "        best_val_loss = float('inf')\n",
    "\n",
    "        for epoch in tqdm(range(args.epochs), desc=f\"Training {condition} trial {trial+1}\"):\n",
    "            train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "            val_loss = evaluate(model, val_loader, criterion, device)\n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                torch.save(model.state_dict(), 'best_model.pth')\n",
    "            \n",
    "            if (epoch+1) % 10 == 0:\n",
    "                print(f'Epoch {epoch+1}/{args.epochs} | Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f}')\n",
    "\n",
    "        model.load_state_dict(torch.load('best_model.pth'))\n",
    "        def evaluate_with_metrics(model, loader, device):\n",
    "            model.eval()\n",
    "            total_mse = 0\n",
    "            total_mape = 0\n",
    "            count = 0\n",
    "            with torch.no_grad():\n",
    "                for X_batch, y_batch in loader:\n",
    "                    X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                    outputs = model(X_batch)\n",
    "                    y_true = y_batch.cpu().numpy()\n",
    "                    y_pred = outputs.cpu().numpy()\n",
    "\n",
    "                    total_mse += ((y_true - y_pred)**2).sum()\n",
    "                    epsilon = 1e-10\n",
    "                    total_mape += np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "                    count += y_true.size\n",
    "            \n",
    "            rmse = np.sqrt(total_mse / count)\n",
    "            mape = 100 * total_mape / count\n",
    "            \n",
    "            return rmse, mape\n",
    "\n",
    "        def plot_true_vs_predicted(model, test_files, device, condition_name, trial_num, args):\n",
    "            plt.figure(figsize=(15, 8))  \n",
    "            all_true_values = []\n",
    "            all_pred_values = []\n",
    "            \n",
    "            for test_file in test_files:\n",
    "                test_data = load_battery_data(test_file)\n",
    "                X, y = create_sequences(test_data, args.window_size, args.prediction_steps, args.step_size)\n",
    "                X_t = torch.FloatTensor(X).to(device)\n",
    "                \n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    preds = model(X_t).cpu().numpy()\n",
    "                for i in range(len(y)):\n",
    "                    all_true_values.append(y[i])\n",
    "                    all_pred_values.append(preds[i])\n",
    "            \n",
    "            for i in range(len(all_true_values)):\n",
    "                plt.plot(range(i, i + len(all_true_values[i])), \n",
    "                        all_true_values[i], \n",
    "                        color='blue', alpha=0.5, \n",
    "                        label='True Values' if i == 0 else \"\")\n",
    "            \n",
    "            for i in range(len(all_pred_values)):\n",
    "                plt.plot(range(i, i + len(all_pred_values[i])), \n",
    "                        all_pred_values[i], \n",
    "                        color='red', alpha=0.5, \n",
    "                        label='Predictions' if i == 0 else \"\")\n",
    "            \n",
    "            plt.title(f'True vs Predicted Capacity (Overlapped)\\nCondition: {condition_name} - Trial {trial_num}')\n",
    "            plt.xlabel('Time Step')\n",
    "            plt.ylabel('Capacity (Normalized)')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        test_rmse, test_mape = evaluate_with_metrics(model, test_loader, device)\n",
    "        print(f'\\nTest Metrics: RMSE = {test_rmse:.6f}, MAPE = {test_mape:.2f}%')\n",
    "        plot_true_vs_predicted(model, test_files, device, args.condition, trial+1, args)\n",
    "        results.loc[len(results)] = {\n",
    "            'condition': condition,\n",
    "            'trial': trial+1,\n",
    "            'train_loss': train_losses[-1],\n",
    "            'val_loss': val_losses[-1],\n",
    "            'test_rmse': test_rmse,\n",
    "            'test_mape': test_mape\n",
    "        }\n",
    "\n",
    "        results.to_csv('battery_prediction_results-UL-NCA.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
